{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFN0wvfLQtwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "PyTorch-based audio processing and AR modeling pipeline.\n",
        "\n",
        "This annotated version adds clear, practical comments and docstrings explaining:\n",
        "- Global numerical policy and threading constraints\n",
        "- Audio loading with robust fallbacks and resampling\n",
        "- Spectral diagnostics (PSD/Welch, spectral flatness, aliasing)\n",
        "- AR estimation (closed-form low-memory, statsmodels reference, Yule–Walker sweep)\n",
        "- AR neural network (linear and small MLP variants), training loop choices\n",
        "- Post-processing (CSV trace, PCA + KMeans clustering) and the orchestration flow\n",
        "\n",
        "The code is organized in sections; each public function includes a concise docstring\n",
        "(describing inputs/outputs) and critical implementation notes appear inline.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "ood4abyERLFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from typing import Optional, Tuple, Union, Dict, Any, List\n",
        "import gc\n",
        "import math\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ===== Global numerical policy (single source of truth) =====\n",
        "# Enforce CPU and high-precision numerics everywhere for consistency/reproducibility.\n",
        "# Float64 improves stability of linear algebra (Cholesky, eigen-decompositions),\n",
        "# and complex128 pairs naturally with float64 for eigendecomposition on companion matrices.\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "DTYPE = torch.float64\n",
        "CDTYPE = torch.complex128  # complex dtype paired with DTYPE\n",
        "\n",
        "# Optional dependencies (import softly so the pipeline remains usable with a subset)\n",
        "try:\n",
        "    import torchaudio\n",
        "except ImportError:\n",
        "    torchaudio = None\n",
        "\n",
        "try:\n",
        "    import soundfile as sf\n",
        "except ImportError:\n",
        "    sf = None\n",
        "\n",
        "try:\n",
        "    from scipy.io import wavfile as scipy_wav\n",
        "except ImportError:\n",
        "    scipy_wav = None\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.ar_model import AutoReg\n",
        "    STATSMODELS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    AutoReg = None\n",
        "    STATSMODELS_AVAILABLE = False\n",
        "\n",
        "# Plotting (optional)\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    MATPLOTLIB_AVAILABLE = True\n",
        "except Exception:\n",
        "    MATPLOTLIB_AVAILABLE = False\n",
        "\n",
        "# For clustering (optional, for PCA/KMeans visualization)\n",
        "try:\n",
        "    from sklearn.cluster import KMeans\n",
        "    SKLEARN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SKLEARN_AVAILABLE = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"statsmodels\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Simple global thread knobs (no per-thread env edits)\n",
        "# -----------------------\n",
        "def _set_global_threads():\n",
        "    \"\"\"Set conservative global thread counts for PyTorch to avoid oversubscription.\n",
        "\n",
        "    We avoid touching process env vars or using per-thread mutation.\n",
        "    - Use up to half of logical cores (>=1) for compute threads\n",
        "    - Set interop threads to 1\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Conservative: cap to half logical cores (>=1), interop = 1\n",
        "        torch.set_num_threads(max(1, (os.cpu_count() or 8) // 2))\n",
        "        torch.set_num_interop_threads(1)\n",
        "    except Exception:\n",
        "        pass\n",
        "_set_global_threads()\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# First-use numerics warm-up\n",
        "# -----------------------\n",
        "@torch.no_grad()\n",
        "def _warmup_numerics():\n",
        "    \"\"\"Touch common linear-algebra and FFT kernels once to amortize JIT/allocator overhead.\n",
        "\n",
        "    This makes the first real call later less bursty in latency-sensitive contexts.\n",
        "    \"\"\"\n",
        "    a = torch.randn(8192, dtype=DTYPE, device=DEVICE)\n",
        "    _ = torch.fft.rfft(a)\n",
        "    M = torch.randn(8, 8, dtype=DTYPE, device=DEVICE)\n",
        "    G = M.T @ M + 1e-6 * torch.eye(8, dtype=DTYPE, device=DEVICE)\n",
        "    L = torch.linalg.cholesky(G)\n",
        "    _ = torch.cholesky_solve(torch.randn(8, 1, dtype=DTYPE, device=DEVICE), L)\n",
        "    C = torch.zeros((4, 4), dtype=CDTYPE, device=DEVICE)\n",
        "    C[0, :] = torch.rand(4, dtype=DTYPE, device=DEVICE).to(CDTYPE)\n",
        "    for i in range(1, 4):\n",
        "        C[i, i - 1] = 1\n",
        "    _ = torch.linalg.eig(C)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# File presence guard\n",
        "# -----------------------\n",
        "def _filter_existing_files(audio_files: list, base_path: Union[str, Path]):\n",
        "    \"\"\"Split a list of file names into (existing, missing) under a base path.\"\"\"\n",
        "    base = Path(base_path)\n",
        "    existing, missing = [], []\n",
        "    for fn in audio_files:\n",
        "        fp = base / fn\n",
        "        if fp.is_file():\n",
        "            existing.append(fn)\n",
        "        else:\n",
        "            missing.append(fn)\n",
        "    return existing, missing\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Memory-savvy utilities\n",
        "# -----------------------\n",
        "def _pick_channel_inplace(waveform: torch.Tensor, mode: str = \"first\") -> torch.Tensor:\n",
        "    \"\"\"Select mono channel view without extra allocation when possible.\n",
        "\n",
        "    Args:\n",
        "        waveform: Tensor of shape (channels, samples).\n",
        "        mode: \"first\" (default) or \"mean\" across channels.\n",
        "    Returns:\n",
        "        (1, samples) tensor.\n",
        "    \"\"\"\n",
        "    if waveform.ndim != 2:\n",
        "        raise ValueError(f\"Expected (channels, samples), got {tuple(waveform.shape)}\")\n",
        "    if waveform.size(0) == 1 or mode == \"first\":\n",
        "        return waveform.narrow(0, 0, 1)\n",
        "    return waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "\n",
        "def _int_normalize_inplace(x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "    \"\"\"Convert integer PCM → float64 in [-1, 1] (in-place where reasonable).\n",
        "\n",
        "    Handles common integer formats; falls back to range derived from dtype limits.\n",
        "    Keeps result on global DEVICE and DTYPE.\n",
        "    \"\"\"\n",
        "    if x.dtype.is_floating_point:\n",
        "        return x.to(dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "    if x.dtype == torch.int16:\n",
        "        x = x.to(dtype=DTYPE, device=DEVICE).div_(32768.0)\n",
        "    elif x.dtype == torch.int32:\n",
        "        x = x.to(dtype=DTYPE, device=DEVICE).div_(2147483648.0)\n",
        "    elif x.dtype == torch.uint8:\n",
        "        x = x.to(dtype=DTYPE, device=DEVICE).sub_(128.0).div_(128.0)\n",
        "    else:\n",
        "        info = torch.iinfo(x.dtype)\n",
        "        denom = float(max(abs(info.min), abs(info.max)))\n",
        "        x = x.to(dtype=DTYPE, device=DEVICE).div_(denom)\n",
        "\n",
        "    return x.clamp_(-1.0, 1.0)\n",
        "\n",
        "\n",
        "def _cheap_decimate_if_integer_ratio(\n",
        "    waveform: torch.Tensor, sr: int, target_sr: Optional[int]\n",
        ") -> Tuple[torch.Tensor, int]:\n",
        "    \"\"\"Downsample by exact integer factor via stride if sr % target_sr == 0.\n",
        "\n",
        "    Fast, alias-prone if high-frequency energy exists; upstream caller should\n",
        "    check whiteness/aliasing risk before using aggressive decimation.\n",
        "    \"\"\"\n",
        "    if target_sr is None or sr == target_sr:\n",
        "        return waveform, sr\n",
        "    if target_sr > sr:\n",
        "        return waveform, sr\n",
        "    if sr % target_sr != 0:\n",
        "        return waveform, sr\n",
        "    factor = sr // target_sr\n",
        "    decimated = waveform[..., ::factor].contiguous()\n",
        "    return decimated, target_sr\n",
        "\n",
        "\n",
        "def _resample_if_needed(\n",
        "    waveform: torch.Tensor,\n",
        "    sr: int,\n",
        "    target_sr: Optional[int],\n",
        "    allow_integer_decimation: bool = True\n",
        ") -> Tuple[torch.Tensor, int]:\n",
        "    \"\"\"Resample to target SR using torchaudio if available, else integer decimation.\n",
        "\n",
        "    Returns original if target_sr is None, equals sr, or no backend is available.\n",
        "    \"\"\"\n",
        "    if target_sr is None or sr == target_sr:\n",
        "        return waveform, sr\n",
        "\n",
        "    if allow_integer_decimation:\n",
        "        wf2, sr2 = _cheap_decimate_if_integer_ratio(waveform, sr, target_sr)\n",
        "        if sr2 == target_sr:\n",
        "            return wf2, sr2\n",
        "\n",
        "    if torchaudio is not None:\n",
        "        try:\n",
        "            return torchaudio.functional.resample(waveform, sr, target_sr), target_sr\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Resampling failed: {e}. Returning original audio at {sr} Hz.\")\n",
        "            return waveform, sr\n",
        "\n",
        "    warnings.warn(f\"Requested resample {sr}→{target_sr} Hz but no backend; keeping original.\")\n",
        "    return waveform, sr\n",
        "\n",
        "\n",
        "def _load_audio_with_fallback(\n",
        "    p: Path,\n",
        "    target_sr: Optional[int],\n",
        "    mono_mode: str,\n",
        "    max_duration_s: Optional[float],\n",
        "    verbose: bool,\n",
        ") -> Tuple[torch.Tensor, int]:\n",
        "    \"\"\"Load audio via torchaudio → soundfile → scipy.io.wavfile fallback chain.\n",
        "\n",
        "    Ensures return tensor is (channels, samples), float32 initially; resampling and\n",
        "    mono selection are applied before returning.\n",
        "    \"\"\"\n",
        "    # 1) torchaudio\n",
        "    if torchaudio is not None:\n",
        "        try:\n",
        "            waveform, sr = torchaudio.load(str(p))  # float32 CPU\n",
        "            if max_duration_s is not None:\n",
        "                max_samples = int(sr * max_duration_s)\n",
        "                waveform = waveform[..., :max_samples]\n",
        "            waveform = _pick_channel_inplace(waveform, mode=mono_mode)\n",
        "            waveform, sr = _resample_if_needed(waveform, sr, target_sr)\n",
        "            return waveform.contiguous(), sr\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                warnings.warn(f\"torchaudio.load failed for '{p.name}': {e}\")\n",
        "\n",
        "    # 2) soundfile\n",
        "    if sf is not None:\n",
        "        try:\n",
        "            if max_duration_s is None:\n",
        "                data, sr = sf.read(str(p), dtype=\"float32\", always_2d=True)\n",
        "            else:\n",
        "                with sf.SoundFile(str(p), \"r\") as f:\n",
        "                    sr = f.samplerate\n",
        "                    frames = min(int(sr * max_duration_s), len(f))\n",
        "                    data = f.read(frames=frames, dtype=\"float32\", always_2d=True)\n",
        "            waveform = torch.from_numpy(np.ascontiguousarray(data.T))\n",
        "            waveform = _pick_channel_inplace(waveform, mode=mono_mode)\n",
        "            waveform, sr = _resample_if_needed(waveform, sr, target_sr)\n",
        "            return waveform.contiguous(), sr\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                warnings.warn(f\"soundfile failed for '{p.name}': {e}\")\n",
        "\n",
        "    # 3) SciPy WAV (mmap)\n",
        "    if scipy_wav is not None and p.suffix.lower() == \".wav\":\n",
        "        try:\n",
        "            sr, data = scipy_wav.read(str(p), mmap=True)\n",
        "            if max_duration_s is not None:\n",
        "                max_samples = int(sr * max_duration_s)\n",
        "                data = data[:max_samples, ...] if data.ndim == 2 else data[:max_samples]\n",
        "            if data.ndim == 1:\n",
        "                t = torch.from_numpy(np.asarray(data))\n",
        "                t = _int_normalize_inplace(t).unsqueeze(0)\n",
        "            else:\n",
        "                t = torch.from_numpy(np.asarray(data))\n",
        "                t = _int_normalize_inplace(t)\n",
        "                t = t.t().contiguous()\n",
        "            t = _pick_channel_inplace(t, mode=mono_mode)\n",
        "            t, sr = _resample_if_needed(t, sr, target_sr)\n",
        "            return t.contiguous(), sr\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                warnings.warn(f\"scipy.io.wavfile failed for '{p.name}': {e}\")\n",
        "\n",
        "    loaders = [\n",
        "        f\"torchaudio: {'✓' if torchaudio is not None else '✗'}\",\n",
        "        f\"soundfile: {'✓' if sf is not None else '✗'}\",\n",
        "        f\"scipy.io.wavfile: {'✓' if scipy_wav is not None else '✗'}\",\n",
        "    ]\n",
        "    raise RuntimeError(\n",
        "        f\"Failed to load audio file: '{p}'\\n\"\n",
        "        f\"Available loaders:\\n  • \" + \"\\n  • \".join(loaders) +\n",
        "        \"\\nInstall 'soundfile' for reliable loading: pip install soundfile\"\n",
        "    )\n",
        "\n",
        "\n",
        "def read_wav(\n",
        "    file_path: Union[str, Path],\n",
        "    target_sr: Optional[int] = None,\n",
        "    verbose: bool = True,\n",
        "    mono_mode: str = \"first\",\n",
        "    max_duration_s: Optional[float] = None,\n",
        ") -> Tuple[torch.Tensor, int]:\n",
        "    \"\"\"High-level WAV reader that returns waveform on (DEVICE, DTYPE).\n",
        "\n",
        "    Returns:\n",
        "        waveform: Tensor (1, samples) float64 on CPU\n",
        "        sample_rate: int\n",
        "    \"\"\"\n",
        "    p = Path(file_path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"Audio file not found: '{p}'\")\n",
        "    if not p.is_file():\n",
        "        raise ValueError(f\"Path is not a file: '{p}'\")\n",
        "    if not os.access(p, os.R_OK):\n",
        "        raise PermissionError(f\"File is not readable: '{p}'\")\n",
        "\n",
        "    waveform, sample_rate = _load_audio_with_fallback(\n",
        "        p, target_sr=target_sr, mono_mode=mono_mode, max_duration_s=max_duration_s, verbose=verbose\n",
        "    )\n",
        "\n",
        "    # Normalize to global dtype/device for downstream consistency\n",
        "    waveform = waveform.to(dtype=DTYPE, device=DEVICE).contiguous()\n",
        "\n",
        "    if verbose:\n",
        "        dur = waveform.shape[1] / sample_rate\n",
        "        print(f\"Sample rate: {sample_rate:,} Hz\")\n",
        "        print(f\"Shape: {tuple(waveform.shape)} (channels, samples)\")\n",
        "        print(f\"Duration: {dur:.3f} s\")\n",
        "        mn = float(waveform.min()); mx = float(waveform.max())\n",
        "        print(f\"Data range: [{mn:.3f}, {mx:.3f}]\")\n",
        "\n",
        "    return waveform, sample_rate\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Spectral helpers & pre-whitening/aliasing check (low-mem)\n",
        "# ---------------------------------------------\n",
        "_WIN_CACHE: Dict[Tuple[int, str], torch.Tensor] = {}\n",
        "\n",
        "@torch.no_grad()\n",
        "def _get_window(M: int, kind: str = \"hann\") -> torch.Tensor:\n",
        "    \"\"\"Retrieve and cache window tensors on the global (DEVICE, DTYPE).\"\"\"\n",
        "    key = (M, kind)\n",
        "    w = _WIN_CACHE.get(key)\n",
        "    if w is not None and w.dtype == DTYPE and w.device == DEVICE:\n",
        "        return w\n",
        "    if kind == \"hann\":\n",
        "        w = torch.hann_window(M, dtype=DTYPE, periodic=True, device=DEVICE)\n",
        "    elif kind == \"hamming\":\n",
        "        w = torch.hamming_window(M, dtype=DTYPE, periodic=True, device=DEVICE)\n",
        "    else:\n",
        "        w = torch.ones(M, dtype=DTYPE, device=DEVICE)\n",
        "    _WIN_CACHE[key] = w\n",
        "    return w\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def psd_torch(x: torch.Tensor, sr: int, n_fft: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Single-shot periodogram (rFFT) power spectral density estimate.\n",
        "\n",
        "    Returns (freqs, Pxx) with densities normalized by (n_fft * sr).\n",
        "    \"\"\"\n",
        "    if x.ndim != 1:\n",
        "        raise ValueError(\"psd_torch expects a 1-D tensor\")\n",
        "    x = x.to(dtype=DTYPE, device=DEVICE)\n",
        "    if n_fft is None:\n",
        "        n_fft = min(1 << (x.numel() - 1).bit_length(), 1 << 17)\n",
        "    X = torch.fft.rfft(x, n=n_fft)\n",
        "    Pxx = (X.abs() ** 2) / (n_fft * sr)\n",
        "    try:\n",
        "        freqs = torch.fft.rfftfreq(n_fft, d=1.0 / sr).to(dtype=DTYPE, device=DEVICE)\n",
        "    except AttributeError:\n",
        "        freqs = torch.linspace(0, sr / 2, steps=X.numel(), dtype=DTYPE, device=DEVICE)\n",
        "    return freqs, Pxx.to(dtype=DTYPE)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def welch_psd_torch(\n",
        "    x: torch.Tensor,\n",
        "    sr: int,\n",
        "    *,\n",
        "    seglen: Optional[int] = None,\n",
        "    noverlap: Optional[int] = None,\n",
        "    n_fft: Optional[int] = None,\n",
        "    window: str = \"hann\",\n",
        "    detrend: bool = True,\n",
        "    avg: str = \"mean\",          # \"mean\" or \"median\"\n",
        "    block_windows: int = 32,\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Welch PSD with block processing to keep memory bound small.\n",
        "\n",
        "    - Detrends by mean subtraction if requested\n",
        "    - Supports mean/median aggregation across segments\n",
        "    - Uses cached window and explicit normalization U = sum(w^2)\n",
        "    \"\"\"\n",
        "    x = x.to(dtype=DTYPE, device=DEVICE)\n",
        "    N = x.numel()\n",
        "    if N == 0:\n",
        "        return torch.empty(0, dtype=DTYPE, device=DEVICE), torch.empty(0, dtype=DTYPE, device=DEVICE)\n",
        "    if detrend:\n",
        "        x = x - x.mean()\n",
        "\n",
        "    if seglen is None:\n",
        "        seglen = min(8192, N)\n",
        "        seglen = 1 << (seglen - 1).bit_length()\n",
        "        seglen = min(seglen, N)\n",
        "    if seglen <= 1:\n",
        "        return torch.empty(0, dtype=DTYPE, device=DEVICE), torch.empty(0, dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "    if noverlap is None:\n",
        "        noverlap = seglen // 2\n",
        "    step = max(1, seglen - noverlap)\n",
        "    if n_fft is None:\n",
        "        n_fft = seglen\n",
        "\n",
        "    windows = x.unfold(0, seglen, step)  # (K, seglen)\n",
        "    K = int(windows.shape[0])\n",
        "    if K == 0:\n",
        "        return psd_torch(x, sr, n_fft=n_fft)\n",
        "\n",
        "    w = _get_window(seglen, kind=window)\n",
        "    U = (w * w).sum()\n",
        "\n",
        "    acc = None\n",
        "    meds = []\n",
        "\n",
        "    for start in range(0, K, block_windows):\n",
        "        end = min(start + block_windows, K)\n",
        "        Wb = windows[start:end].contiguous()\n",
        "        Xb = torch.fft.rfft(Wb * w, n=n_fft, dim=1)\n",
        "        Pxx_b = (Xb.abs() ** 2) / (U * sr)  # density per segment\n",
        "        # Double energy of non-DC/non-Nyquist bins to convert to one-sided PSD\n",
        "        if n_fft % 2 == 0:\n",
        "            Pxx_b[:, 1:-1] *= 2.0\n",
        "        else:\n",
        "            Pxx_b[:, 1:] *= 2.0\n",
        "\n",
        "        if avg == \"median\":\n",
        "            meds.append(Pxx_b.median(dim=0).values)\n",
        "        else:\n",
        "            s = Pxx_b.sum(dim=0)\n",
        "            acc = s if acc is None else (acc + s)\n",
        "\n",
        "        del Wb, Xb, Pxx_b\n",
        "\n",
        "    if avg == \"median\":\n",
        "        Pxx = torch.stack(meds, dim=0).median(dim=0).values\n",
        "    else:\n",
        "        Pxx = acc / K\n",
        "\n",
        "    freqs = torch.fft.rfftfreq(n_fft, d=1.0 / sr).to(dtype=DTYPE, device=DEVICE)\n",
        "    return freqs, Pxx.to(dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def spectral_flatness(Pxx: torch.Tensor, eps: float = 1e-18) -> float:\n",
        "    \"\"\"Geometric/Arithmetic mean ratio of spectrum; 1≈white, 0≈tonal.\"\"\"\n",
        "    gm = torch.exp(torch.mean(torch.log(Pxx.to(dtype=DTYPE, device=DEVICE) + eps)))\n",
        "    am = torch.mean(Pxx.to(dtype=DTYPE, device=DEVICE) + eps)\n",
        "    return float((gm / am).clamp_min(0.0).clamp_max(1.0).item())\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def spectral_flatness_bandlimited(\n",
        "    freqs: torch.Tensor,\n",
        "    Pxx: torch.Tensor,\n",
        "    f_lo_ratio: float = 0.02,\n",
        "    f_hi_ratio: float = 0.98,\n",
        "    trim: float = 0.0,\n",
        "    eps: float = 1e-18\n",
        ") -> float:\n",
        "    \"\"\"Band-limit SFM to avoid DC/Nyquist artifacts and optionally trim tails.\"\"\"\n",
        "    freqs = freqs.to(dtype=DTYPE, device=DEVICE)\n",
        "    Pxx = Pxx.to(dtype=DTYPE, device=DEVICE)\n",
        "    if freqs.numel() == 0:\n",
        "        return 0.0\n",
        "    fmax = float(freqs[-1].item())\n",
        "    f_lo = f_lo_ratio * fmax\n",
        "    f_hi = f_hi_ratio * fmax\n",
        "    band = (freqs >= f_lo) & (freqs <= f_hi)\n",
        "    p = Pxx[band]\n",
        "    if p.numel() == 0:\n",
        "        p = Pxx\n",
        "    if trim > 0 and p.numel() > 10:\n",
        "        k = int(trim * p.numel())\n",
        "        p = torch.sort(p).values[k: p.numel() - k]\n",
        "    gm = torch.exp(torch.mean(torch.log(p + eps)))\n",
        "    am = torch.mean(p + eps)\n",
        "    return float((gm / am).clamp(0.0, 1.0).item())\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def acf_torch(x: torch.Tensor, max_lag: int) -> torch.Tensor:\n",
        "    \"\"\"Unbiased (by denominator) normalized autocorrelation up to max_lag.\"\"\"\n",
        "    x = x.to(dtype=DTYPE, device=DEVICE)\n",
        "    x = x - x.mean()\n",
        "    denom = torch.sum(x * x) + 1e-18\n",
        "    ac = [torch.tensor(1.0, dtype=DTYPE, device=DEVICE)]\n",
        "    for k in range(1, max_lag + 1):\n",
        "        ac.append(torch.dot(x[:-k], x[k:]) / denom)\n",
        "    return torch.stack(ac, dim=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ljung_box_q(acf: torch.Tensor, n: int, m: int) -> float:\n",
        "    \"\"\"Compute Ljung–Box Q statistic from ACF(1..m) to test whiteness.\"\"\"\n",
        "    ks = torch.arange(1, m + 1, dtype=DTYPE, device=DEVICE)\n",
        "    Q = n * (n + 2) * torch.sum((acf[1:m+1].to(dtype=DTYPE, device=DEVICE) ** 2) / (n - ks))\n",
        "    return float(Q.item())\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def alias_fraction_from_psd(freqs: torch.Tensor, Pxx: torch.Tensor, sr: int, factor: int) -> float:\n",
        "    \"\"\"Fraction of spectral energy above the new Nyquist if downsampling by `factor`.\"\"\"\n",
        "    if factor <= 1:\n",
        "        return 0.0\n",
        "    freqs = freqs.to(dtype=DTYPE, device=DEVICE)\n",
        "    Pxx = Pxx.to(dtype=DTYPE, device=DEVICE)\n",
        "    new_nyq = sr / (2.0 * factor)\n",
        "    m = freqs > new_nyq\n",
        "    num = float(Pxx[m].sum().item())\n",
        "    den = float(Pxx.sum().item()) + 1e-24\n",
        "    return num / den\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def decimation_aliasing_risk(x: torch.Tensor, sr: int, factor: int, n_fft: Optional[int] = None) -> float:\n",
        "    \"\"\"Shortcut: compute aliasing fraction for a raw 1-D signal.\"\"\"\n",
        "    if factor <= 1:\n",
        "        return 0.0\n",
        "    freqs, Pxx = psd_torch(x, sr, n_fft=n_fft)\n",
        "    return alias_fraction_from_psd(freqs, Pxx, sr, factor)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def prewhitening_check(x: torch.Tensor, sr: int, candidate_factors: List[int] = [2, 3, 4], verbose: bool = True) -> Dict[str, Any]:\n",
        "    \"\"\"Assess whether the signal is near-white and safe to decimate.\n",
        "\n",
        "    Combines: Welch PSD, band-limited spectral flatness, Ljung–Box Q, and\n",
        "    aliasing fraction for candidate integer downsampling factors.\n",
        "    \"\"\"\n",
        "    x = x.detach().to(dtype=DTYPE, device=DEVICE)\n",
        "    x_eval = x[-131072:] if x.numel() > 131072 else x\n",
        "\n",
        "    freqs, Pxx = welch_psd_torch(\n",
        "        x_eval, sr,\n",
        "        seglen=min(8192, x_eval.numel()),\n",
        "        noverlap=None,\n",
        "        n_fft=None,\n",
        "        window=\"hann\",\n",
        "        detrend=True,\n",
        "        avg=\"mean\",\n",
        "        block_windows=32\n",
        "    )\n",
        "\n",
        "    sfm = spectral_flatness_bandlimited(freqs, Pxx, f_lo_ratio=0.02, f_hi_ratio=0.98, trim=0.0)\n",
        "\n",
        "    n = x_eval.numel()\n",
        "    max_lag = min(40, max(10, n // 50))\n",
        "    ac = acf_torch(x_eval, max_lag=max_lag)\n",
        "    Q = ljung_box_q(ac, n=n, m=min(20, max_lag))\n",
        "\n",
        "    alias = {f: alias_fraction_from_psd(freqs, Pxx, sr, f) for f in candidate_factors}\n",
        "\n",
        "    suggestion = \"No decimation (insufficient whiteness)\"\n",
        "    safe = [f for f, frac in alias.items() if frac < 0.02]\n",
        "    if sfm > 0.6 and len(safe) > 0:\n",
        "        suggestion = f\"Integer decimation by {max(safe)} OK (SFM={sfm:.2f})\"\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Spectral Flatness (band-limited Welch): {sfm:.3f} (≈1 is white)\")\n",
        "        print(f\"Ljung-Box Q: {Q:.2f} (larger suggests non-white)\")\n",
        "        for f, frac in alias.items():\n",
        "            print(f\"Aliasing fraction at factor {f}: {100*frac:.3f}%\")\n",
        "        print(f\"Suggestion: {suggestion}\")\n",
        "\n",
        "    return {\n",
        "        \"sfm\": sfm,\n",
        "        \"ljung_box_Q\": Q,\n",
        "        \"aliasing_fraction\": {int(k): float(v) for k, v in alias.items()},\n",
        "        \"suggestion\": suggestion,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Reverse-index cache\n",
        "# -----------------------\n",
        "_REV_IDX: Dict[int, torch.Tensor] = {}\n",
        "@torch.no_grad()\n",
        "def _rev_idx(P: int) -> torch.Tensor:\n",
        "    \"\"\"Return cached reverse index [P-1,..,0] to avoid reallocations in folds.\"\"\"\n",
        "    t = _REV_IDX.get(P)\n",
        "    if t is None:\n",
        "        t = torch.arange(P - 1, -1, -1, dtype=torch.long, device=DEVICE)\n",
        "        _REV_IDX[P] = t\n",
        "    return t\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Vectorized linear AR forecasting (companion eigen)\n",
        "# -----------------------\n",
        "@torch.no_grad()\n",
        "def _build_companion(params64: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Construct the AR(P) companion matrix in complex128 for eigen methods.\"\"\"\n",
        "    P = int(params64.numel())\n",
        "    C = torch.zeros((P, P), dtype=CDTYPE, device=DEVICE)\n",
        "    C[0, :P] = params64.to(CDTYPE)\n",
        "    for i in range(1, P):\n",
        "        C[i, i-1] = 1.0\n",
        "    return C\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eigen_forecast_ar(params: torch.Tensor, last_ctx: torch.Tensor, steps: int) -> torch.Tensor:\n",
        "    \"\"\"Closed-form AR forecast y_{t+h} using eigendecomposition of companion matrix.\n",
        "\n",
        "    Args:\n",
        "        params: AR coefficients (most-recent-first) length P; accepts NumPy or Tensor.\n",
        "        last_ctx: last P samples (1-D); accepts NumPy or Tensor.\n",
        "        steps: number of future steps to forecast (>=0).\n",
        "    Returns:\n",
        "        Tensor[steps] on (DEVICE, DTYPE).\n",
        "    \"\"\"\n",
        "    if not isinstance(params, torch.Tensor):\n",
        "        params = torch.as_tensor(params, dtype=DTYPE, device=DEVICE)\n",
        "    else:\n",
        "        params = params.to(dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "    if not isinstance(last_ctx, torch.Tensor):\n",
        "        last_ctx = torch.as_tensor(last_ctx, dtype=DTYPE, device=DEVICE)\n",
        "    else:\n",
        "        last_ctx = last_ctx.to(dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "    P = int(params.numel())\n",
        "    if steps <= 0:\n",
        "        return torch.zeros((0,), dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "    ctx_mrf = torch.flip(last_ctx, dims=[0]).to(CDTYPE)\n",
        "    C = _build_companion(params)\n",
        "    eigvals, V = torch.linalg.eig(C)\n",
        "    c = torch.linalg.solve(V, ctx_mrf)\n",
        "    alpha = V[0, :]\n",
        "\n",
        "    h = torch.arange(1, steps + 1, dtype=DTYPE, device=DEVICE)\n",
        "    lam_h = eigvals.unsqueeze(0) ** h.unsqueeze(1)\n",
        "    y_h = (alpha * (lam_h * c)).sum(dim=1).real\n",
        "    return y_h.to(dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Low-memory AR(P) (Gram accumulation + Cholesky)\n",
        "# -----------------------\n",
        "@torch.no_grad()\n",
        "def _ar_blockwise_gram_b(x64: torch.Tensor, P: int, block: int = 200_000) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "    \"\"\"Accumulate normal equations G=X^T X and b=X^T y for AR(P) in blocks.\n",
        "\n",
        "    Windows shape: (M, P+1) where last column is y and first P columns are lags.\n",
        "    \"\"\"\n",
        "    N = x64.numel()\n",
        "    M = N - P\n",
        "    if M <= 0:\n",
        "        return torch.zeros((P, P), dtype=DTYPE, device=DEVICE), torch.zeros(P, dtype=DTYPE, device=DEVICE), 0\n",
        "\n",
        "    windows = x64.unfold(0, P + 1, 1)\n",
        "    G = torch.zeros((P, P), dtype=DTYPE, device=DEVICE)\n",
        "    b = torch.zeros(P, dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "    idx = _rev_idx(P)\n",
        "    for start in range(0, M, block):\n",
        "        end = min(start + block, M)\n",
        "        Wb = windows[start:end]\n",
        "        yb = Wb[:, -1]\n",
        "        Xb = Wb[:, :-1].index_select(1, idx).contiguous()\n",
        "        G += Xb.T @ Xb\n",
        "        b += Xb.T @ yb\n",
        "        del Wb, Xb, yb\n",
        "        gc.collect()\n",
        "\n",
        "    return G, b, M\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _ar_rss_from_params(x64: torch.Tensor, P: int, params64: torch.Tensor, block: int = 200_000, step: int = 1) -> Tuple[float, int]:\n",
        "    \"\"\"Compute residual sum of squares for given params with block evaluation.\"\"\"\n",
        "    N = x64.numel()\n",
        "    N = x64.numel()\n",
        "    M = N - P\n",
        "    if M <= 0:\n",
        "        return float(\"inf\"), 0\n",
        "\n",
        "    windows = x64.unfold(0, P + 1, 1)\n",
        "    rss = 0.0\n",
        "    idx = _rev_idx(P)\n",
        "    for start in range(0, M, block * step):\n",
        "        end = min(start + block * step, M)\n",
        "        Wb = windows[start:end:step]\n",
        "        yb = Wb[:, -1].contiguous()\n",
        "        Xb = Wb[:, :-1].index_select(1, idx).contiguous()\n",
        "        resid = yb - (Xb @ params64)\n",
        "        rss += float((resid * resid).sum().item())\n",
        "        del Wb, Xb, yb, resid\n",
        "        gc.collect()\n",
        "\n",
        "    return rss, (M + step - 1) // step\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def fit_ar_closed_form_lowmem(\n",
        "    waveform: torch.Tensor,\n",
        "    P: int,\n",
        "    samples_to_predict: int = 100,\n",
        "    lambda_reg: float = 0.0,\n",
        "    verbose: bool = True,\n",
        "    block: Optional[int] = None,\n",
        "    vectorized_forecast: bool = True,\n",
        ") -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[float], Optional[float]]:\n",
        "    \"\"\"Estimate AR(P) coefficients by solving normal equations with Cholesky.\n",
        "\n",
        "    Memory-frugal: builds Gram matrix and RHS in blocks, then solves once.\n",
        "    Optionally performs vectorized multi-step forecasting via eigen method.\n",
        "    Returns (params, preds, AICc, BIC) or (None, ... ) on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        x = waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0, 0, 1)[0]\n",
        "        x64 = x.detach().to(DEVICE, dtype=DTYPE)\n",
        "        N = x64.numel()\n",
        "        if N <= P + 1:\n",
        "            if verbose:\n",
        "                print(\"Not enough samples for the requested lags\")\n",
        "            return None, None, None, None\n",
        "\n",
        "        if block is None:\n",
        "            block = min(262_144, max(65_536, N // 10))\n",
        "\n",
        "        G, b, M = _ar_blockwise_gram_b(x64, P, block=block)\n",
        "        if M == 0:\n",
        "            return None, None, None, None\n",
        "\n",
        "        if lambda_reg and lambda_reg > 0.0:\n",
        "            G = G + (lambda_reg * torch.eye(P, dtype=DTYPE, device=DEVICE))\n",
        "\n",
        "        try:\n",
        "            L = torch.linalg.cholesky(G)\n",
        "            params = torch.cholesky_solve(b.unsqueeze(1), L).squeeze(1)\n",
        "        except RuntimeError:\n",
        "            jitter = (1e-8 * torch.trace(G) / max(P, 1)).item()\n",
        "            G = G + jitter * torch.eye(P, dtype=DTYPE, device=DEVICE)\n",
        "            try:\n",
        "                L = torch.linalg.cholesky(G)\n",
        "                params = torch.cholesky_solve(b.unsqueeze(1), L).squeeze(1)\n",
        "            except RuntimeError:\n",
        "                params = torch.linalg.solve(G, b)\n",
        "\n",
        "        rss, n = _ar_rss_from_params(x64, P, params, block=block, step=1)\n",
        "\n",
        "        k = P\n",
        "        if rss <= 0.0:\n",
        "            aicc = bic = float(\"inf\")\n",
        "        else:\n",
        "            sigma2 = rss / n\n",
        "            loglik = -0.5 * n * (np.log(2 * np.pi * sigma2) + 1.0)\n",
        "            aic = -2.0 * loglik + 2.0 * k\n",
        "            bic = -2.0 * loglik + np.log(n) * k\n",
        "            aicc = aic + (2.0 * k * (k + 1.0)) / max(n - k - 1.0, 1.0)\n",
        "\n",
        "        preds = None\n",
        "        if samples_to_predict > 0:\n",
        "            if vectorized_forecast:\n",
        "                # Call the corrected function which now returns a tensor\n",
        "                preds = eigen_forecast_ar(params, last_ctx=x64[-P:], steps=samples_to_predict)\n",
        "            else:\n",
        "                ctx_mrf = torch.flip(x64[-P:], dims=[0]).clone()\n",
        "                preds_list = []\n",
        "                for _ in range(samples_to_predict):\n",
        "                    yhat = (ctx_mrf * params).sum().item()\n",
        "                    preds_list.append(yhat)\n",
        "                    ctx_mrf = torch.cat([torch.tensor([yhat], dtype=DTYPE, device=DEVICE), ctx_mrf[:-1]])\n",
        "                # Return a PyTorch tensor\n",
        "                preds = torch.tensor(preds_list, dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "        if verbose:\n",
        "            np.set_printoptions(precision=9, suppress=False)\n",
        "            print(f\"[Low-mem AR] P={P} | N={N:,} | AICc={aicc:.3f} | BIC={bic:.3f}\")\n",
        "            if P <= 12:\n",
        "                print(\"AR coeffs (most-recent-first):\", params.detach().cpu().numpy())\n",
        "\n",
        "        # Return PyTorch tensors\n",
        "        return params, preds, float(aicc), float(bic)\n",
        "\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Error in low-mem AR fit: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# -----------------------\n",
        "# Classical AR (statsmodels) — safe wrapper (small N)\n",
        "# -----------------------\n",
        "def fit_ar_model_statsmodels(\n",
        "    waveform: torch.Tensor,\n",
        "    P: int,\n",
        "    samples_to_predict: int = 100,\n",
        "    verbose: bool = True,\n",
        ") -> Tuple[Optional[object], Optional[np.ndarray]]:\n",
        "    \"\"\"Reference AutoReg(P) using statsmodels (CPU, NumPy space).\n",
        "\n",
        "    Limits: used only for smaller N (threshold controlled by caller).\n",
        "    Returns fitted model and NumPy predictions (if requested).\n",
        "    \"\"\"\n",
        "    if not STATSMODELS_AVAILABLE:\n",
        "        return None, None\n",
        "    try:\n",
        "        x_np = (waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0,0,1)[0]).detach().cpu().numpy()\n",
        "        if verbose:\n",
        "            print(f\"[statsmodels] Fitting AR(P={P}) on {x_np.shape[0]:,} samples\")\n",
        "        model = AutoReg(x_np, lags=P, trend=\"n\")\n",
        "        model_fit = model.fit()\n",
        "        start_idx = x_np.shape[0]\n",
        "        end_idx = start_idx + samples_to_predict - 1\n",
        "        preds = model_fit.predict(start=start_idx, end=end_idx)\n",
        "        if verbose:\n",
        "            print(f\"AIC: {model_fit.aic:.3f}, BIC: {model_fit.bic:.3f}\")\n",
        "        return model_fit, preds\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"statsmodels AR failed: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Yule–Walker + Levinson–Durbin (fast order sweep)\n",
        "# -----------------------\n",
        "@torch.no_grad()\n",
        "def _acf_fft_1d(x64: torch.Tensor, Pmax: int) -> torch.Tensor:\n",
        "    \"\"\"Compute normalized autocorrelation via FFT convolution trick (O(n log n)).\"\"\"\n",
        "    n = int(x64.numel())\n",
        "    m = 1 << (2 * n - 1).bit_length()\n",
        "    X = torch.fft.rfft(x64, n=m)\n",
        "    S = (X * X.conj()).real\n",
        "    acf_full = torch.fft.irfft(S, n=m)[:n]\n",
        "    r0 = acf_full[0].clamp_min(1e-18)\n",
        "    acf_full = acf_full / r0\n",
        "    return acf_full[: Pmax + 1].contiguous().to(dtype=DTYPE, device=DEVICE)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _levinson_durbin_all_orders(r: torch.Tensor) -> List[Tuple[torch.Tensor, torch.Tensor]]:\n",
        "    \"\"\"Levinson–Durbin recursion returning (coeffs, error) for orders 1..Pmax.\"\"\"\n",
        "    Pmax = int(r.numel() - 1)\n",
        "    a = torch.zeros(Pmax, dtype=DTYPE, device=DEVICE)\n",
        "    E = r[0].clone()\n",
        "    out = []\n",
        "    for p in range(1, Pmax + 1):\n",
        "        if p == 1:\n",
        "            k = -r[1] / E\n",
        "            a[0] = k\n",
        "            E = E * (1 - k * k)\n",
        "        else:\n",
        "            k = -(r[p] + (a[:p-1] * r[1:p].flip(0)).sum()) / E\n",
        "            a[:p-1] = a[:p-1] + k * a[:p-1].flip(0)\n",
        "            a[p-1] = k\n",
        "            E = E * (1 - k * k)\n",
        "        out.append((a[:p].flip(0).clone(), E.clamp_min(1e-18)))\n",
        "    return out\n",
        "\n",
        "\n",
        "def select_ar_order_aicc_yw(\n",
        "    waveform: torch.Tensor,\n",
        "    P_min: int = 1,\n",
        "    P_max: int = 20,\n",
        "    verbose: bool = True,\n",
        "    patience: int = 3,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Sweep AR order using Yule–Walker/Levinson–Durbin and choose by AICc.\n",
        "\n",
        "    Early-stop once `patience` consecutive orders fail to improve best AICc past\n",
        "    the current best order.\n",
        "    \"\"\"\n",
        "    x = waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0,0,1)[0]\n",
        "    x64 = x.detach().to(DEVICE, dtype=DTYPE)\n",
        "    N = int(x64.numel())\n",
        "    if N <= P_min + 1:\n",
        "        return {\"records\": [], \"best\": {\"P\": None, \"AICc\": float(\"inf\"), \"BIC\": float(\"inf\")}}\n",
        "\n",
        "    r = _acf_fft_1d(x64 - x64.mean(), P_max)\n",
        "    seq = _levinson_durbin_all_orders(r)\n",
        "\n",
        "    records = []\n",
        "    best = {\"P\": None, \"AICc\": float(\"inf\"), \"BIC\": float(\"inf\")}\n",
        "    worse_in_a_row = 0\n",
        "    for p in range(P_min, P_max + 1):\n",
        "        a_p, E_p = seq[p - 1]\n",
        "        n_eff = max(N - p, 1)\n",
        "        sigma2 = float(E_p)\n",
        "        loglik = -0.5 * n_eff * (np.log(2 * np.pi * sigma2) + 1.0)\n",
        "        aic = -2.0 * loglik + 2.0 * p\n",
        "        bic = -2.0 * loglik + np.log(n_eff) * p\n",
        "        aicc = aic + (2.0 * p * (p + 1.0)) / max(n_eff - p - 1.0, 1.0)\n",
        "        records.append((p, aicc, bic))\n",
        "        if aicc < best[\"AICc\"] - 1e-12:\n",
        "            best = {\"P\": p, \"AICc\": aicc, \"BIC\": bic}\n",
        "            worse_in_a_row = 0\n",
        "        else:\n",
        "            worse_in_a_row += 1\n",
        "            if worse_in_a_row >= patience and (best[\"P\"] is not None) and (p > best[\"P\"]):\n",
        "                if verbose:\n",
        "                    print(f\"[YW sweep] Early stop at P={p} (patience={patience})\")\n",
        "                break\n",
        "\n",
        "    if verbose and records:\n",
        "        print(f\"[YW sweep] Evaluated P={records[0][0]}..{records[-1][0]} | Best by AICc: P={best['P']} (AICc={best['AICc']:.3f})\")\n",
        "\n",
        "    return {\"records\": records, \"best\": best}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Order selection via AICc (sequential; no per-thread env tweaks)\n",
        "# -----------------------\n",
        "def select_ar_order_aicc_lowmem(\n",
        "    waveform: torch.Tensor,\n",
        "    P_min: int = 1,\n",
        "    P_max: int = 20,\n",
        "    lambda_reg: float = 0.0,\n",
        "    verbose: bool = True,\n",
        "    block: Optional[int] = None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Alternate sweep using the low-memory closed-form fitter each order.\n",
        "    Sequential sweep to avoid thread-related races. If you need parallelism,\n",
        "    prefer process-level parallel outside this function.\n",
        "    \"\"\"\n",
        "    x = waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0,0,1)[0]\n",
        "    N = int(x.numel())\n",
        "    records = []\n",
        "    best = {\"P\": None, \"AICc\": float(\"inf\"), \"BIC\": float(\"inf\")}\n",
        "\n",
        "    Ps = [P for P in range(P_min, P_max + 1) if N > P + 1]\n",
        "    for P in Ps:\n",
        "        _, _, aicc, bic = fit_ar_closed_form_lowmem(\n",
        "            waveform, P, samples_to_predict=0, lambda_reg=lambda_reg, verbose=False, block=block\n",
        "        )\n",
        "        if aicc is not None:\n",
        "            records.append((P, aicc, bic))\n",
        "            if aicc < best[\"AICc\"]:\n",
        "                best = {\"P\": P, \"AICc\": aicc, \"BIC\": bic}\n",
        "\n",
        "    records.sort(key=lambda t: t[0])\n",
        "    if verbose and records:\n",
        "        print(f\"[Order sweep] Evaluated P={records[0][0]}..{records[-1][0]} | Best by AICc: P={best['P']} (AICc={best['AICc']:.3f})\")\n",
        "    return {\"records\": records, \"best\": best}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# AR Neural Network (PyTorch) — CPU-only, consistent dtype\n",
        "# -----------------------\n",
        "class ARNN(torch.nn.Module):\n",
        "    \"\"\"A tiny AR-NN: either exact linear AR or a 1-hidden-layer MLP.\n",
        "\n",
        "    - If hidden_size == 0: exactly a Linear(lags, 1) layer (optionally initialized\n",
        "      from the closed-form solution for faster convergence and traceability).\n",
        "    - If hidden_size > 0: Linear → ReLU → Linear.\n",
        "    \"\"\"\n",
        "    def __init__(self, lags: int, hidden_size: int = 0, bias: bool = False, dtype: torch.dtype = DTYPE):\n",
        "        super().__init__()\n",
        "        self.lags = lags\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        if hidden_size > 0:\n",
        "            self.net = torch.nn.Sequential(\n",
        "                torch.nn.Linear(lags, hidden_size, bias=True, dtype=dtype, device=DEVICE),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(hidden_size, 1, bias=True, dtype=dtype, device=DEVICE),\n",
        "            )\n",
        "        else:\n",
        "            self.net = torch.nn.Linear(lags, 1, bias=bias, dtype=dtype, device=DEVICE)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x).squeeze(-1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _roll_predict(model: ARNN, last_context: torch.Tensor, steps: int) -> np.ndarray:\n",
        "    \"\"\"Iteratively roll forecasts forward using the model in the time domain.\"\"\"\n",
        "    model.eval()\n",
        "    ctx = torch.flip(last_context.to(dtype=DTYPE, device=DEVICE), dims=[0]).clone()\n",
        "    preds = []\n",
        "    for _ in range(steps):\n",
        "        with torch.no_grad():\n",
        "            y_hat_t = model(ctx.unsqueeze(0))\n",
        "        y_hat = float(y_hat_t.item())\n",
        "        preds.append(y_hat)\n",
        "        ctx = torch.cat([torch.tensor([y_hat], dtype=DTYPE, device=DEVICE), ctx[:-1]], dim=0)\n",
        "    return np.asarray(preds, dtype=np.float64)\n",
        "\n",
        "\n",
        "def fit_ar_nn(\n",
        "    waveform: torch.Tensor,\n",
        "    lags: int = 10,\n",
        "    samples_to_predict: int = 100,\n",
        "    hidden_size: int = 0,\n",
        "    epochs: int = 5,\n",
        "    batch_size: int = 8192,\n",
        "    lr: float = 1e-2,\n",
        "    weight_decay: float = 0.0,\n",
        "    grad_clip: float = 1.0,\n",
        "    device: Optional[str] = \"cpu\",   # kept for signature; enforced to CPU\n",
        "    verbose: bool = True,\n",
        "    *,\n",
        "    include_bias: bool = False,\n",
        "    use_exact_linear: bool = True,\n",
        "    train_dtype: torch.dtype = DTYPE,  # <<< unified dtype\n",
        "    max_windows_for_nn: Optional[int] = None,\n",
        "    shuffle: bool = False,\n",
        ") -> Tuple[Optional[dict], Optional[np.ndarray], Optional[np.ndarray]]:\n",
        "    \"\"\"Train ARNN on overlapping windows; return state_dict, preds, and linear weights.\n",
        "\n",
        "    Uses unfold to create training windows lazily; supports downsampling of windows\n",
        "    via `step` when there are too many. If `hidden_size==0` and `use_exact_linear`,\n",
        "    we initialize from the closed-form AR solution for fast convergence and auditability.\n",
        "    \"\"\"\n",
        "    if waveform.ndim != 2:\n",
        "        raise ValueError(f\"Expected waveform (C, N), got {tuple(waveform.shape)}\")\n",
        "\n",
        "    # Enforce global device\n",
        "    device = DEVICE\n",
        "\n",
        "    x = waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0, 0, 1)[0]\n",
        "    x64 = x.detach().to(device=device, dtype=DTYPE)\n",
        "    N = x64.numel()\n",
        "    if N <= lags + 1:\n",
        "        if verbose:\n",
        "            print(\"Not enough samples for the requested lags\")\n",
        "        return None, None, None\n",
        "\n",
        "    windows = x64.unfold(0, lags + 1, 1)\n",
        "    M = int(windows.shape[0])\n",
        "\n",
        "    if max_windows_for_nn is None:\n",
        "        max_windows_for_nn = min(2_000_000, max(1_000_000, M // 2))\n",
        "\n",
        "    step = max(1, math.ceil(M / max_windows_for_nn)) if (max_windows_for_nn and M > max_windows_for_nn) else 1\n",
        "\n",
        "    model = ARNN(lags=lags, hidden_size=hidden_size, bias=include_bias, dtype=train_dtype).to(device=device)\n",
        "\n",
        "    linear_weights = None\n",
        "\n",
        "    # Optional exact linear init for the pure linear case (no bias)\n",
        "    if hidden_size == 0 and use_exact_linear and not include_bias:\n",
        "        G, b, _ = _ar_blockwise_gram_b(x64, lags, block=200_000)\n",
        "        try:\n",
        "            L = torch.linalg.cholesky(G)\n",
        "            sol = torch.cholesky_solve(b.unsqueeze(1), L).squeeze(1)\n",
        "        except RuntimeError:\n",
        "            jitter = (1e-8 * torch.trace(G) / max(lags, 1)).item()\n",
        "            G = G + jitter * torch.eye(lags, dtype=DTYPE, device=DEVICE)\n",
        "            try:\n",
        "                L = torch.linalg.cholesky(G)\n",
        "                sol = torch.cholesky_solve(b.unsqueeze(1), L).squeeze(1)\n",
        "            except RuntimeError:\n",
        "                sol = torch.linalg.solve(G, b)\n",
        "        with torch.no_grad():\n",
        "            model.net.weight.data.copy_(sol.to(dtype=train_dtype, device=device).unsqueeze(0))\n",
        "            if model.net.bias is not None:\n",
        "                model.net.bias.zero_()\n",
        "        linear_weights = sol.detach().cpu().numpy().astype(np.float64)\n",
        "        if epochs <= 0:\n",
        "            last_ctx = x64[-lags:]\n",
        "            preds_future = _roll_predict(model, last_context=last_ctx, steps=samples_to_predict)\n",
        "            if verbose:\n",
        "                np.set_printoptions(precision=9)\n",
        "                print(\"AR-NN (linear) exact weights (DTYPE) initialized.\")\n",
        "            return model.state_dict(), preds_future, linear_weights\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    # Training with explicit grad context\n",
        "    idx_rev = _rev_idx(lags)\n",
        "    for ep in range(1, epochs + 1):\n",
        "        epoch_loss = 0.0\n",
        "        count = 0\n",
        "        model.train()\n",
        "        # Optional tiny offset to get a simple form of shuffling across epochs\n",
        "        offset = int(torch.randint(low=0, high=min(10_000, max(1, step)), size=(1,), device=DEVICE).item()) if shuffle else 0\n",
        "\n",
        "        start = offset\n",
        "        while start < M:\n",
        "            end = min(start + batch_size * step, M)\n",
        "            with torch.no_grad():\n",
        "                Wb = windows[start:end:step]\n",
        "                Xb = Wb[:, :lags].index_select(1, idx_rev).contiguous().to(device=device, dtype=train_dtype)\n",
        "                yb = Wb[:, -1].contiguous().to(device=device, dtype=train_dtype)\n",
        "\n",
        "            with torch.enable_grad():\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                yhat = model(Xb)\n",
        "                loss = loss_fn(yhat, yb)\n",
        "                loss.backward()\n",
        "                if grad_clip and grad_clip > 0:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                opt.step()\n",
        "\n",
        "            batch_n = int(Wb.shape[0])\n",
        "            epoch_loss += float(loss.item()) * batch_n\n",
        "            count += batch_n\n",
        "\n",
        "            del Wb, Xb, yb, yhat, loss\n",
        "            gc.collect()\n",
        "            start = end\n",
        "\n",
        "        epoch_loss = epoch_loss / max(count, 1)\n",
        "\n",
        "    last_ctx = x64[-lags:]\n",
        "    preds_future = _roll_predict(model, last_context=last_ctx, steps=samples_to_predict)\n",
        "\n",
        "    if hidden_size == 0:\n",
        "        # Return learned linear weights for traceability\n",
        "        w = model.net.weight.detach().to('cpu', dtype=DTYPE).squeeze(0).numpy().astype(np.float64)\n",
        "        if model.net.bias is not None:\n",
        "            b = model.net.bias.detach().to('cpu', dtype=DTYPE).numpy().astype(np.float64)\n",
        "            linear_weights = np.concatenate([w, b], axis=0)\n",
        "        else:\n",
        "            linear_weights = w\n",
        "\n",
        "    return model.state_dict(), preds_future, linear_weights\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Post-processing: save & cluster AR parameters\n",
        "# -----------------------\n",
        "def _rows_from_results(results: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Extract CSV rows from the orchestration result dictionary.\"\"\"\n",
        "    rows = []\n",
        "    for fname, item in results.items():\n",
        "        if not item or not item.get(\"success\"):\n",
        "            continue\n",
        "        ar = item.get(\"ar\", {})\n",
        "        params_full = ar.get(\"params_full\", None)\n",
        "        if params_full is None:\n",
        "            continue\n",
        "        row = {\n",
        "            \"file_name\": fname,\n",
        "            \"P\": int(ar.get(\"P\")) if ar.get(\"P\") is not None else None,\n",
        "            \"method\": \"statsmodels\" if (\"aic\" in ar or \"bic\" in ar) else (\"lowmem\" if (\"AICc\" in ar or \"BIC\" in ar) else \"unknown\"),\n",
        "            \"sample_rate\": float(item.get(\"sample_rate\", float(\"nan\"))),\n",
        "            \"duration_sec\": float(item.get(\"duration\", float(\"nan\"))),\n",
        "            \"time_sec\": float(item.get(\"time_sec\", float(\"nan\"))),\n",
        "            \"AIC\": float(ar.get(\"aic\", float(\"nan\"))),\n",
        "            \"BIC\": float(ar.get(\"bic\", float(\"nan\"))),\n",
        "            \"AICc\": float(ar.get(\"AICc\", float(\"nan\"))),\n",
        "            \"params_json\": json.dumps([float(x) for x in np.asarray(params_full, dtype=np.float64).tolist()]),\n",
        "        }\n",
        "        nn = item.get(\"nn_ar\", {})\n",
        "        row[\"nn_P\"] = int(nn.get(\"P\")) if nn.get(\"P\") is not None else None\n",
        "        row[\"nn_hidden_size\"] = int(nn.get(\"hidden_size\")) if nn.get(\"hidden_size\") is not None else None\n",
        "        nn_weights = nn.get(\"linear_weights_plus_bias\", None)\n",
        "        row[\"nn_params_json\"] = json.dumps([float(x) for x in np.asarray(nn_weights, dtype=np.float64).tolist()]) if nn_weights is not None else None\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "\n",
        "\n",
        "def save_ar_params_csv(results: Dict[str, Any], out_csv_path: Union[str, Path]) -> int:\n",
        "    \"\"\"Write AR parameter trace to CSV for downstream analysis/visualization.\"\"\"\n",
        "    rows = _rows_from_results(results)\n",
        "    if not rows:\n",
        "        print(\"⚠️  No AR parameters to save.\")\n",
        "        return 0\n",
        "    out_csv_path = Path(out_csv_path)\n",
        "    out_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with out_csv_path.open(\"w\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(\n",
        "            f,\n",
        "            fieldnames=[\"file_name\",\"P\",\"method\",\"sample_rate\",\"duration_sec\",\"time_sec\",\"AIC\",\"BIC\",\"AICc\",\"params_json\",\"nn_P\",\"nn_hidden_size\",\"nn_params_json\"]\n",
        "        )\n",
        "        writer.writeheader()\n",
        "        for r in rows:\n",
        "            writer.writerow(r)\n",
        "    print(f\"📁 Saved AR parameter trace to: {out_csv_path}  ({len(rows)} rows)\")\n",
        "    return len(rows)\n",
        "\n",
        "\n",
        "def _read_ar_params_csv(csv_path: Union[str, Path]) -> Tuple[List[str], np.ndarray, np.ndarray]:\n",
        "    \"\"\"Load params CSV back into (file_names, param-matrix padded to maxP, Pvec).\"\"\"\n",
        "    file_names = []\n",
        "    params_list = []\n",
        "    P_list = []\n",
        "    with Path(csv_path).open(\"r\", newline=\"\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            try:\n",
        "                fname = row[\"file_name\"]\n",
        "                P = int(row[\"P\"])\n",
        "                params = json.loads(row[\"params_json\"])\n",
        "                if not isinstance(params, list):\n",
        "                    continue\n",
        "                file_names.append(fname)\n",
        "                P_list.append(P)\n",
        "                params_list.append(np.asarray(params, dtype=np.float64))\n",
        "            except Exception:\n",
        "                continue\n",
        "    if not params_list:\n",
        "        return [], np.empty((0,0), dtype=np.float64), np.empty((0,), dtype=np.int64)\n",
        "    maxP = max(len(p) for p in params_list)\n",
        "    X = np.zeros((len(params_list), maxP), dtype=np.float64)\n",
        "    for i, p in enumerate(params_list):\n",
        "        L = min(len(p), maxP)\n",
        "        X[i, :L] = p[:L]\n",
        "    return file_names, X, np.asarray(P_list, dtype=np.int64)\n",
        "\n",
        "\n",
        "def _pca_2d(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"Simple PCA: center, SVD, take first two components and project rows.\"\"\"\n",
        "    mu = X.mean(axis=0, keepdims=True)\n",
        "    Xc = X - mu\n",
        "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
        "    X2d = U[:, :2] * S[:2]\n",
        "    comps = Vt[:2, :]\n",
        "    return X2d, comps, mu\n",
        "\n",
        "\n",
        "def _kmeans2(X: np.ndarray, k: int = 2, n_init: int = 10, max_iter: int = 100, seed: int = 42) -> Tuple[np.ndarray, np.ndarray, float]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    best_inertia = np.inf\n",
        "    best_labels = None\n",
        "    best_centers = None\n",
        "    for _ in range(n_init):\n",
        "        idx = rng.choice(X.shape[0], size=k, replace=False)\n",
        "        centers = X[idx].copy()\n",
        "        for _it in range(max_iter):\n",
        "            d2 = ((X[:, None, :] - centers[None, :, :]) ** 2).sum(axis=2)\n",
        "            labels = np.argmin(d2, axis=1)\n",
        "            new_centers = np.vstack([X[labels == j].mean(axis=0) if np.any(labels == j) else centers[j] for j in range(k)])\n",
        "            shift = np.linalg.norm(new_centers - centers)\n",
        "            centers = new_centers\n",
        "            if shift < 1e-8:\n",
        "                break\n",
        "        inertia = ((X - centers[labels]) ** 2).sum()\n",
        "        if inertia < best_inertia:\n",
        "            best_inertia = inertia\n",
        "            best_labels = labels.copy()\n",
        "            best_centers = centers.copy()\n",
        "    return best_labels, best_centers, float(best_inertia)\n",
        "\n",
        "\n",
        "def cluster_and_visualize(params_csv: Union[str, Path], out_png: Union[str, Path]) -> Dict[str, Any]:\n",
        "    files, X, Pvec = _read_ar_params_csv(params_csv)\n",
        "    if X.size == 0 or X.shape[0] < 2:\n",
        "        print(\"⚠️  Not enough data to cluster/plot.\")\n",
        "        return {\"ok\": False}\n",
        "    X2d, comps, mu = _pca_2d(X)\n",
        "    if SKLEARN_AVAILABLE:\n",
        "        kmeans = KMeans(n_clusters=2, n_init=20, max_iter=200, random_state=123)\n",
        "        labels = kmeans.fit_predict(X2d)\n",
        "        centers = kmeans.cluster_centers_\n",
        "        inertia = float(kmeans.inertia_)\n",
        "    else:\n",
        "        labels, centers, inertia = _kmeans2(X2d, k=2, n_init=20, max_iter=200, seed=123)\n",
        "    if MATPLOTLIB_AVAILABLE:\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        plt.scatter(X2d[:, 0], X2d[:, 1], s=18, alpha=0.85, label=\"files\")\n",
        "        plt.scatter(centers[:, 0], centers[:, 1], s=80, marker=\"X\", label=\"centers\")\n",
        "        plt.xlabel(\"PCA 1\")\n",
        "        plt.ylabel(\"PCA 2\")\n",
        "        plt.title(\"AR Params: PCA (k=2 clusters)\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        out_png = Path(out_png)\n",
        "        out_png.parent.mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(out_png, dpi=160)\n",
        "        plt.close()\n",
        "        print(f\"📈 Saved PCA scatter to: {out_png}\")\n",
        "    else:\n",
        "        print(\"⚠️  matplotlib not available; skipping plot.\")\n",
        "    counts = {int(i): int((labels == i).sum()) for i in range(2)}\n",
        "    return {\"ok\": True, \"n\": int(X.shape[0]), \"cluster_counts\": counts, \"inertia\": inertia}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Orchestrator\n",
        "# -----------------------\n",
        "def process_audio_files(\n",
        "    audio_files: list,\n",
        "    base_path: Union[str, Path] = \"/content\",\n",
        "    max_lags: int = 10,\n",
        "    samples_to_predict: int = 100,\n",
        "    target_sr: Optional[int] = None,\n",
        "    mono_mode: str = \"first\",\n",
        "    max_duration_s: Optional[float] = None,\n",
        "    keep_model: bool = False,\n",
        "    verbose: bool = True,\n",
        "    # --- AR-NN options ---\n",
        "    use_nn_ar: bool = True,\n",
        "    nn_hidden_size: int = 0,\n",
        "    nn_epochs: int = 5,\n",
        "    nn_batch_size: int = 8192,\n",
        "    nn_lr: float = 1e-2,\n",
        "    nn_weight_decay: float = 0.0,\n",
        "    nn_grad_clip: float = 1.0,\n",
        "    nn_device: Optional[str] = \"cpu\",   # kept for API; enforced CPU\n",
        "    # --- Order selection ---\n",
        "    do_order_selection: bool = True,\n",
        "    order_P_min: int = 1,\n",
        "    order_P_max: int = 24,\n",
        "    order_method: str = \"yw\",  # \"yw\" or \"lowmem\"\n",
        "    # --- Other ---\n",
        "    do_prewhitening_check: bool = True,\n",
        "    lambda_reg: float = 0.0,\n",
        "    statsmodels_threshold_samples: int = 300_000,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Process multiple audio files: load, analyze AR models,\n",
        "    optionally use neural nets for AR, and collect results.\n",
        "    \"\"\"\n",
        "    base_path = Path(base_path)\n",
        "    results: Dict[str, Any] = {}\n",
        "\n",
        "    if base_path.exists():\n",
        "        if verbose:\n",
        "            try:\n",
        "                entries = os.listdir(base_path)\n",
        "                print(f\"Files in {base_path}: {sorted(entries)[:50]}{' ...' if len(entries) > 50 else ''}\")\n",
        "            except Exception:\n",
        "                pass\n",
        "    else:\n",
        "        print(f\"⚠️  Base path does not exist: {base_path}\")\n",
        "        return {}\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nProcessing {len(audio_files)} audio files...\")\n",
        "\n",
        "    _warmup_numerics()\n",
        "\n",
        "    for i, file_name in enumerate(audio_files, 1):\n",
        "        file_path = base_path / file_name\n",
        "        if verbose:\n",
        "            print(f\"\\n[{i}/{len(audio_files)}] {file_name}\")\n",
        "\n",
        "        if not file_path.is_file():\n",
        "            if verbose:\n",
        "                print(f\"↪️  Skipping missing file: {file_path}\")\n",
        "            results[file_name] = {\"success\": False, \"error\": f\"File not found: {str(file_path)}\"}\n",
        "            continue\n",
        "\n",
        "        waveform = None\n",
        "        preds = None\n",
        "        nn_state = None\n",
        "        nn_preds = None\n",
        "        nn_weights = None\n",
        "        t0 = time.perf_counter()\n",
        "\n",
        "        try:\n",
        "            waveform, sr = read_wav(\n",
        "                file_path,\n",
        "                target_sr=target_sr,\n",
        "                verbose=verbose,\n",
        "                mono_mode=mono_mode,\n",
        "                max_duration_s=max_duration_s,\n",
        "            )\n",
        "\n",
        "            item: Dict[str, Any] = {\n",
        "                \"success\": True,\n",
        "                \"sample_rate\": sr,\n",
        "                \"duration\": waveform.shape[1] / sr,\n",
        "            }\n",
        "\n",
        "            if do_prewhitening_check:\n",
        "                pw = prewhitening_check(waveform[0], sr, candidate_factors=[2, 3, 4], verbose=verbose)\n",
        "                item[\"prewhitening\"] = {\n",
        "                    \"sfm\": pw[\"sfm\"],\n",
        "                    \"ljung_box_Q\": pw[\"ljung_box_Q\"],\n",
        "                    \"aliasing_fraction\": {int(k): float(v) for k, v in pw[\"aliasing_fraction\"].items()},\n",
        "                    \"suggestion\": pw[\"suggestion\"],\n",
        "                }\n",
        "\n",
        "            if do_order_selection:\n",
        "                if order_method.lower() == \"yw\":\n",
        "                    sel = select_ar_order_aicc_yw(waveform, P_min=order_P_min, P_max=order_P_max, verbose=verbose, patience=3)\n",
        "                else:\n",
        "                    sel = select_ar_order_aicc_lowmem(\n",
        "                        waveform, P_min=order_P_min, P_max=order_P_max, lambda_reg=lambda_reg, verbose=verbose, block=None\n",
        "                    )\n",
        "                item[\"order_selection\"] = {\n",
        "                    \"best_P\": int(sel[\"best\"][\"P\"]) if sel[\"best\"][\"P\"] is not None else None,\n",
        "                    \"best_AICc\": float(sel[\"best\"][\"AICc\"]) if sel[\"best\"][\"P\"] is not None else None,\n",
        "                    \"best_BIC\": float(sel[\"best\"][\"BIC\"]) if sel[\"best\"][\"P\"] is not None else None,\n",
        "                    \"method\": order_method.lower(),\n",
        "                }\n",
        "                chosen_P = item[\"order_selection\"][\"best_P\"] or max_lags\n",
        "            else:\n",
        "                chosen_P = max_lags\n",
        "\n",
        "            N = int((waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0,0,1)[0]).numel())\n",
        "            use_sm = STATSMODELS_AVAILABLE and (N <= statsmodels_threshold_samples)\n",
        "\n",
        "            if use_sm:\n",
        "                model_fit, sm_preds = fit_ar_model_statsmodels(\n",
        "                    waveform, P=chosen_P, samples_to_predict=samples_to_predict, verbose=verbose\n",
        "                )\n",
        "                if model_fit is not None:\n",
        "                    full_params = getattr(model_fit, \"params\", None)\n",
        "\n",
        "                    # Prefer vectorized forecast if params available; else use sm_preds\n",
        "                    if full_params is not None and samples_to_predict > 0:\n",
        "                        vec_preds_t = eigen_forecast_ar(\n",
        "                            params=torch.from_numpy(full_params).to(dtype=DTYPE, device=DEVICE),\n",
        "                            last_ctx=(waveform[0] if waveform.shape[0] == 1 else waveform.narrow(0,0,1)[0])[-chosen_P:],\n",
        "                            steps=samples_to_predict,\n",
        "                        )\n",
        "                        vec_preds = vec_preds_t.detach().cpu().numpy()\n",
        "                    else:\n",
        "                        vec_preds = np.asarray(sm_preds, dtype=np.float64) if sm_preds is not None else None\n",
        "\n",
        "                    # Normalize params to numpy for downstream CSV/JSON\n",
        "                    params_head_np = (full_params[:8].astype(np.float64, copy=False)\n",
        "                                      if full_params is not None else None)\n",
        "                    params_full_np = (full_params.astype(np.float64, copy=False)\n",
        "                                      if full_params is not None else None)\n",
        "\n",
        "                    item[\"ar\"] = {\n",
        "                        \"P\": chosen_P,\n",
        "                        \"predictions\": vec_preds,\n",
        "                        \"aic\": float(getattr(model_fit, \"aic\", np.nan)),\n",
        "                        \"bic\": float(getattr(model_fit, \"bic\", np.nan)),\n",
        "                        \"params_head\": params_head_np,\n",
        "                        \"params_full\": params_full_np,\n",
        "                    }\n",
        "                    if keep_model:\n",
        "                        item[\"ar\"][\"model\"] = model_fit\n",
        "                else:\n",
        "                    params, preds, aicc, bic = fit_ar_closed_form_lowmem(\n",
        "                        waveform, P=chosen_P, samples_to_predict=samples_to_predict,\n",
        "                        lambda_reg=lambda_reg, verbose=verbose, block=None, vectorized_forecast=True\n",
        "                    )\n",
        "                    if params is not None:\n",
        "                        item[\"ar\"] = {\n",
        "                            \"P\": chosen_P,\n",
        "                            \"predictions\": (\n",
        "                                preds.detach().cpu().numpy() if isinstance(preds, torch.Tensor)\n",
        "                                else (np.asarray(preds, dtype=np.float64) if preds is not None else None)\n",
        "                            ),\n",
        "                            \"AICc\": aicc,\n",
        "                            \"BIC\": bic,\n",
        "                            \"params_head\": params[:8].detach().cpu().numpy().astype(np.float64, copy=False),\n",
        "                            \"params_full\": params.detach().cpu().numpy().astype(np.float64, copy=False),\n",
        "                        }\n",
        "                    if params is not None:\n",
        "                        item.setdefault(\"ar\", {})\n",
        "                        item[\"ar\"].update({\n",
        "                            \"P\": chosen_P,\n",
        "                            \"predictions\": (preds.detach().cpu().numpy()\n",
        "                                            if isinstance(preds, torch.Tensor) else\n",
        "                                             (np.asarray(preds, dtype=np.float64) if preds is not None else None)),\n",
        "\n",
        "                            \"AICc\": aicc,\n",
        "                            \"BIC\": bic,\n",
        "                            \"params_head\": params[:8].detach().cpu().numpy().astype(np.float64, copy=False),\n",
        "                            \"params_full\": params.detach().cpu().numpy().astype(np.float64, copy=False),\n",
        "                        })\n",
        "\n",
        "            if use_nn_ar:\n",
        "                nn_state, nn_preds, nn_weights = fit_ar_nn(\n",
        "                    waveform,\n",
        "                    lags=chosen_P,\n",
        "                    samples_to_predict=samples_to_predict,\n",
        "                    hidden_size=nn_hidden_size,\n",
        "                    epochs=nn_epochs,\n",
        "                    batch_size=nn_batch_size,\n",
        "                    lr=nn_lr,\n",
        "                    weight_decay=nn_weight_decay,\n",
        "                    grad_clip=nn_grad_clip,\n",
        "                    device=nn_device,  # ignored; enforced CPU\n",
        "                    verbose=verbose,\n",
        "                    include_bias=False,\n",
        "                    use_exact_linear=True,\n",
        "                    train_dtype=DTYPE,\n",
        "                    max_windows_for_nn=None,\n",
        "                    shuffle=False,\n",
        "                )\n",
        "                if nn_state is not None:\n",
        "                    item[\"nn_ar\"] = {\n",
        "                        \"P\": chosen_P,\n",
        "                        \"predictions\": nn_preds,\n",
        "                        \"linear_weights_plus_bias\": nn_weights,\n",
        "                        \"hidden_size\": nn_hidden_size,\n",
        "                        \"state_dict_keys\": list(nn_state.keys()),\n",
        "                    }\n",
        "\n",
        "            item[\"time_sec\"] = time.perf_counter() - t0\n",
        "            results[file_name] = item\n",
        "\n",
        "            if verbose and results[file_name].get(\"success\"):\n",
        "                print(f\"✓ Done: {file_name}  |  time={item['time_sec']:.2f}s\")\n",
        "\n",
        "        except Exception as e:\n",
        "            results[file_name] = {\"success\": False, \"error\": str(e), \"time_sec\": time.perf_counter() - t0}\n",
        "            if verbose:\n",
        "                print(f\"✗ Failed: {file_name}: {e}\")\n",
        "        finally:\n",
        "            del waveform, preds, nn_state, nn_preds, nn_weights\n",
        "            gc.collect()\n",
        "\n",
        "    successful = sum(1 for r in results.values() if r.get(\"success\", False))\n",
        "    if verbose:\n",
        "        print(f\"\\n📊 Summary: {successful}/{len(audio_files)} files processed successfully\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# CLI / Entrypoint\n",
        "# -----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Adjust range as needed\n",
        "    audio_files = [f\"{i}_AUDIO.wav\" for i in range(300, 311)]\n",
        "\n",
        "    possible_paths = [\n",
        "        \"/content\",\n",
        "        \"/work\",\n",
        "        \"/work/cloud_storage/DAIC-WOZ\",\n",
        "        \"/work/syncthing/DAIC-WOZ\",\n",
        "        \".\",\n",
        "    ]\n",
        "\n",
        "    base_path = next((p for p in possible_paths if Path(p).exists()), None)\n",
        "    if base_path is None:\n",
        "        print(\"❌ Could not find audio files in any expected location\")\n",
        "        print(\"Available paths:\", [p for p in possible_paths if Path(p).exists()])\n",
        "    else:\n",
        "        print(f\"Using base path: {base_path}\")\n",
        "\n",
        "        # Prefilter to avoid missing-file crashes\n",
        "        existing_files, missing_files = _filter_existing_files(audio_files, base_path)\n",
        "        if missing_files:\n",
        "            head = \", \".join(missing_files[:10])\n",
        "            more = \"\" if len(missing_files) <= 10 else f\" (+{len(missing_files)-10} more)\"\n",
        "            print(f\"⚠️  Skipping {len(missing_files)} missing files: {head}{more}\")\n",
        "        if not existing_files:\n",
        "            print(\"❌ No matching files found in base_path. Check base_path or filename pattern.\")\n",
        "        else:\n",
        "            # Process\n",
        "            results = process_audio_files(\n",
        "                existing_files,\n",
        "                base_path=base_path,\n",
        "                max_lags=10,\n",
        "                samples_to_predict=128,\n",
        "                target_sr=None,\n",
        "                mono_mode=\"first\",\n",
        "                max_duration_s=None,\n",
        "                keep_model=False,\n",
        "                verbose=True,\n",
        "                # NN-AR controls\n",
        "                use_nn_ar=True,\n",
        "                nn_hidden_size=0,\n",
        "                nn_epochs=8,\n",
        "                nn_batch_size=8192,\n",
        "                nn_lr=3e-3,\n",
        "                nn_weight_decay=1e-4,\n",
        "                nn_grad_clip=1.0,\n",
        "                nn_device=\"cpu\",\n",
        "                # Order selection\n",
        "                do_order_selection=True,\n",
        "                order_P_min=1,\n",
        "                order_P_max=12,\n",
        "                order_method=\"yw\",\n",
        "                # Diagnostics\n",
        "                do_prewhitening_check=True,\n",
        "            )\n",
        "\n",
        "            # Save AR params for traceability\n",
        "            out_dir = Path(base_path) / \"ar_outputs\"\n",
        "            params_csv = out_dir / \"ar_params_trace.csv\"\n",
        "            if not out_dir.exists():\n",
        "                out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            save_ar_params_csv(results, params_csv)\n",
        "\n",
        "            # Cluster and visualize (PCA) from the saved CSV\n",
        "            pca_png = out_dir / \"ar_params_pca_k2.png\"\n",
        "            summary = cluster_and_visualize(params_csv, pca_png)\n",
        "            if summary.get(\"ok\"):\n",
        "                print(f\"Clusters: {summary['cluster_counts']}, inertia={summary['inertia']:.2f}\")\n"
      ],
      "metadata": {
        "id": "0GbSkja8DHXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AudioARNN02 Notebook — Pseudocode Overview\n",
        "\n",
        "This pseudocode summarizes the notebook’s modules, functions, and main pipeline.\n",
        "\n",
        "## Classes\n",
        "- `(class definition present)` → no named classes detected besides function containers.\n",
        "\n",
        "## Functions by Section\n",
        "\n",
        "### Environment & Numerics\n",
        "- **_set_global_threads()**\n",
        "  - Pseudocode:\n",
        "    - Configure numeric/BLAS backends, seeds, dtype/device policies.\n",
        "    - Warm-up FFT/linear algebra ops (optional).\n",
        "\n",
        "- **_warmup_numerics()**\n",
        "  - Pseudocode:\n",
        "    - Initialize numeric system (threading, BLAS/LAPACK warmup).\n",
        "    - Ensure deterministic RNG seeding.\n",
        "\n",
        "---\n",
        "\n",
        "### Audio I/O & Resampling\n",
        "- **_pick_channel_inplace(waveform, mode)**\n",
        "  - Pseudocode:\n",
        "    - Select mono view: first/mean/max-power channel without large copies.\n",
        "\n",
        "- **_int_normalize_inplace(x)**\n",
        "  - Pseudocode:\n",
        "    - If input is integer PCM-like range, scale to [-1, 1] float range.\n",
        "\n",
        "- **_cheap_decimate_if_integer_ratio(...)**\n",
        "  - Pseudocode:\n",
        "    - If integer ratio exists between `sr` and `target_sr`, decimate with anti-alias checks.\n",
        "    - Otherwise, fall back to generic resample.\n",
        "\n",
        "- **_resample_if_needed(...)**\n",
        "  - Pseudocode:\n",
        "    - If `sr != target_sr`, resample using high-quality method.\n",
        "    - Else, return input unchanged.\n",
        "\n",
        "- **_load_audio_with_fallback(...)**\n",
        "  - Pseudocode:\n",
        "    - Attempt primary loader; on failure, try alternative loaders.\n",
        "    - Return waveform and sample rate if successful.\n",
        "\n",
        "- **read_wav(...)**\n",
        "  - Pseudocode:\n",
        "    - Try torchaudio → fallback to soundfile/scipy if needed.\n",
        "    - Optionally resample to `target_sr`.\n",
        "    - Convert to mono per `mono_mode`.\n",
        "    - Normalize/scale as needed.\n",
        "    - Return waveform tensor [C, N], sample rate.\n",
        "\n",
        "---\n",
        "\n",
        "### Spectral Analysis\n",
        "- **_get_window(M, kind=\"hann\")**\n",
        "  - Pseudocode:\n",
        "    - Construct analysis window by name (hann/hamming/...).\n",
        "\n",
        "- **psd_torch(x, sr, n_fft=None)**\n",
        "  - Pseudocode:\n",
        "    - Compute single-segment periodogram via FFT.\n",
        "    - Return (freqs, power spectrum).\n",
        "\n",
        "- **welch_psd_torch(...)**\n",
        "  - Pseudocode:\n",
        "    - Split signal into overlapping windows.\n",
        "    - Window each segment; FFT and power.\n",
        "    - Average across segments to reduce variance.\n",
        "\n",
        "- **spectral_flatness(Pxx, eps)**\n",
        "  - Pseudocode:\n",
        "    - Compute geometric mean / arithmetic mean of PSD to estimate flatness.\n",
        "\n",
        "- **spectral_flatness_bandlimited(...)**\n",
        "  - Pseudocode:\n",
        "    - Restrict PSD to [fmin, fmax] band and compute flatness.\n",
        "\n",
        "---\n",
        "\n",
        "### Statistical Tests & Diagnostics\n",
        "- **acf_torch(x, max_lag)**\n",
        "  - Pseudocode:\n",
        "    - Compute autocorrelation up to `max_lag` using convolution/FFT methods.\n",
        "\n",
        "- **ljung_box_q(acf, n, m)**\n",
        "  - Pseudocode:\n",
        "    - Calculate Ljung–Box Q statistic from ACF to test for residual whiteness.\n",
        "\n",
        "- **alias_fraction_from_psd(freqs, Pxx, sr, factor)**\n",
        "  - Pseudocode:\n",
        "    - Estimate fraction of spectral energy that would alias for given decimation factor.\n",
        "\n",
        "- **decimation_aliasing_risk(x, sr, factor, n_fft=None)**\n",
        "  - Pseudocode:\n",
        "    - Use PSD to quantify alias risk score for candidate decimation factor.\n",
        "\n",
        "- **prewhitening_check(x, sr, candidate_factors, verbose=True)**\n",
        "  - Pseudocode:\n",
        "    - Compute PSD/flatness, Ljung–Box Q, and alias fractions for several factors.\n",
        "    - Return diagnostic dict and suggestion (e.g., safe factor).\n",
        "\n",
        "---\n",
        "\n",
        "### AR Modeling (classical)\n",
        "- **_rev_idx(P)**\n",
        "  - Pseudocode:\n",
        "    - Build reversed indexing tensor for lag vector operations.\n",
        "\n",
        "- **select_ar_order_aicc_yw(waveform, P_min, P_max, ...)**\n",
        "  - Pseudocode:\n",
        "    - For P in [P_min, P_max]:\n",
        "      - Estimate AR(P) via Yule–Walker.\n",
        "      - Compute AICc/BIC.\n",
        "    - Return best order and metrics.\n",
        "\n",
        "- **select_ar_order_aicc_lowmem(waveform, ...)**\n",
        "  - Pseudocode:\n",
        "    - Streaming/blocked covariance estimation.\n",
        "    - Solve regularized normal equations.\n",
        "    - Score candidates by AICc/BIC.\n",
        "\n",
        "- **fit_ar_model_statsmodels(waveform, P, ...)**\n",
        "  - Pseudocode:\n",
        "    - Fit AR model using statsmodels AutoReg.\n",
        "    - Extract params, AIC/BIC, and optional in-sample forecast.\n",
        "\n",
        "- **fit_ar_closed_form_lowmem(waveform, P, ...)**\n",
        "  - Pseudocode:\n",
        "    - Estimate AR params via closed-form (YW/LS) with optional ridge.\n",
        "    - Forecast using recursive/eigen method.\n",
        "    - Return params, preds, AICc/BIC.\n",
        "\n",
        "---\n",
        "\n",
        "### AR Modeling (NN)\n",
        "- **fit_ar_nn(waveform, lags, ...)**\n",
        "  - Pseudocode:\n",
        "    - Prepare sliding windows of length `lags`.\n",
        "    - Train linear/MLP regressor on CPU with gradient clipping.\n",
        "    - Optionally use exact linear layer to match AR.\n",
        "    - Return model state, predictions, weights.\n",
        "\n",
        "---\n",
        "\n",
        "### Forecasting & Utilities\n",
        "- **eigen_forecast_ar(params, last_ctx, steps)**\n",
        "  - Pseudocode:\n",
        "    - Convert AR params to companion matrix.\n",
        "    - Repeatedly multiply state to generate future steps.\n",
        "    - Return forecast vector.\n",
        "\n",
        "---\n",
        "\n",
        "### Persistence, PCA & Clustering\n",
        "- **save_ar_params_csv(results, path)**\n",
        "  - Pseudocode:\n",
        "    - Iterate results dict; extract AR params and metadata.\n",
        "    - Write rows to CSV for downstream analysis.\n",
        "\n",
        "- **_read_ar_params_csv(path)**\n",
        "  - Pseudocode:\n",
        "    - Read CSV; reconstruct file list and parameter matrix.\n",
        "\n",
        "- **_pca_2d(X)**\n",
        "  - Pseudocode:\n",
        "    - Standardize matrix; compute PCA; return 2D projection and components.\n",
        "\n",
        "- **_kmeans2(X, k=2, ...)**\n",
        "  - Pseudocode:\n",
        "    - Manual KMeans: init centers, assign, update until shift<tol.\n",
        "    - Track best inertia across multiple restarts.\n",
        "\n",
        "- **cluster_and_visualize(params_csv, out_png)**\n",
        "  - Pseudocode:\n",
        "    - Read CSV → PCA 2D.\n",
        "    - Run KMeans (sklearn or fallback).\n",
        "    - Plot scatter + centers; save PNG.\n",
        "    - Return cluster counts and inertia.\n",
        "\n",
        "---\n",
        "\n",
        "### Orchestration & CLI\n",
        "- **process_audio_files(audio_files, base_path, ...)**\n",
        "  - Pseudocode:\n",
        "    - For each file:\n",
        "      - Read audio, run prewhitening diagnostics.\n",
        "      - Select AR order (AICc/BIC).\n",
        "      - Fit AR (statsmodels or low-mem).\n",
        "      - Optionally fit NN-AR.\n",
        "      - Store timings and results.\n",
        "    - Save params CSV; run PCA+KMeans; save plot.\n",
        "\n",
        "---\n",
        "\n",
        "## __main__ block\n",
        "- Discover base path and available audio files.\n",
        "- Filter missing files.\n",
        "- Call `process_audio_files` with configured options.\n",
        "- Save AR params CSV.\n",
        "- Run `cluster_and_visualize` and print summary.\n"
      ],
      "metadata": {
        "id": "v6cAxwU2aLWs"
      }
    }
  ]
}